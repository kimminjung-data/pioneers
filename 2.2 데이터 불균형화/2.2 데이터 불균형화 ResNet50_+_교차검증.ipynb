{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 경로 설정\n",
        "train_fail_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_TUBE/iteration_1/train/fail'\n",
        "train_pass_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_TUBE/iteration_1/train/pass'\n",
        "test_fail_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_TUBE/iteration_1/test/fail'\n",
        "test_pass_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_TUBE/iteration_1/test/pass'\n",
        "\n",
        "# 이미지 로드 및 레이블 생성\n",
        "def load_images_from_folder(folder, label):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith('.bmp'):\n",
        "            img_path = os.path.join(folder, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.resize(img, (128, 128))  # 크기 조정\n",
        "            img = remove_glare(img)  # 난반사 보정\n",
        "            img = normalize_image(img)  # 이미지 정규화\n",
        "            img = enhance_contrast(img)  # 대비 향상\n",
        "            img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "            images.append((img_array, label))\n",
        "    return images\n",
        "\n",
        "# 난반사 보정 함수 (CLAHE 사용)\n",
        "def remove_glare(img):\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    cl = clahe.apply(l)\n",
        "    lab = cv2.merge((cl, a, b))\n",
        "    img_no_glare = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "    return img_no_glare\n",
        "\n",
        "# 이미지 정규화 함수\n",
        "def normalize_image(img):\n",
        "    return img / 255.0  # 픽셀 값을 0-1 범위로 정규화\n",
        "\n",
        "# 대비 향상 함수\n",
        "def enhance_contrast(img):\n",
        "    if img.dtype != np.uint8:\n",
        "        img = (img * 255).astype(np.uint8)  # 데이터 타입 변환\n",
        "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
        "    l, a, b = cv2.split(lab)\n",
        "    l = cv2.equalizeHist(l)\n",
        "    lab = cv2.merge((l, a, b))\n",
        "    img_clahe = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "    return img_clahe\n",
        "\n",
        "# 이미지 증강 (줌과 이동 제외)\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,         # 회전\n",
        "    shear_range=0.2,           # 전단 (shear)\n",
        "    horizontal_flip=True,      # 좌우 반전\n",
        "    width_shift_range=0.1,     # 이동 범위 제한\n",
        "    height_shift_range=0.1,    # 이동 범위 제한\n",
        "    fill_mode='nearest'        # 채워질 영역 처리\n",
        ")\n",
        "\n",
        "# Load and preprocess images\n",
        "train_fail_images = load_images_from_folder(train_fail_dir, 0)\n",
        "train_pass_images = load_images_from_folder(train_pass_dir, 1)\n",
        "\n",
        "# 데이터셋 결합\n",
        "train_dataset = train_fail_images + train_pass_images\n",
        "np.random.shuffle(train_dataset)\n",
        "\n",
        "# 이미지와 레이블 분리\n",
        "X_train, y_train = zip(*train_dataset)\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "# SMOTE를 적용하여 불균형 데이터 처리\n",
        "X_train_flattened = X_train.reshape(len(X_train), -1)  # SMOTE 적용을 위해 Flatten\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_flattened, y_train)\n",
        "\n",
        "# Reshape resampled data\n",
        "X_train_resampled = X_train_resampled.reshape(-1, 128, 128, 3)\n",
        "y_train_resampled = to_categorical(y_train_resampled)\n",
        "\n",
        "# 클래스 가중치 계산\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "# ResNet-50 모델 설정\n",
        "def resnet50_model(input_shape):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dense(2, activation='softmax')(x)  # 출력층: 2개의 클래스\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    return model\n",
        "\n",
        "# 모델 정의\n",
        "model = resnet50_model(input_shape=(128, 128, 3))\n",
        "\n",
        "# 모델 동결 (학습하지 않도록)\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 컴파일\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 교차검증 설정\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "fold = 1\n",
        "\n",
        "for train_index, val_index in kf.split(X_train_resampled):\n",
        "    print(f\"\\nTraining fold {fold}...\")\n",
        "    X_train_fold, X_val_fold = X_train_resampled[train_index], X_train_resampled[val_index]\n",
        "    y_train_fold, y_val_fold = y_train_resampled[train_index], y_train_resampled[val_index]\n",
        "\n",
        "    # 데이터 증강 적용\n",
        "    train_generator = datagen.flow(X_train_fold, y_train_fold, batch_size=32)\n",
        "    val_generator = ImageDataGenerator().flow(X_val_fold, y_val_fold, batch_size=32)\n",
        "\n",
        "    # 모델 학습\n",
        "    history = model.fit(train_generator, epochs=10, validation_data=val_generator, class_weight=class_weight_dict)\n",
        "\n",
        "    # 평가\n",
        "    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold)\n",
        "    print(f\"Fold {fold} Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
        "\n",
        "    # 임계값 조정 및 성능 평가\n",
        "    y_val_pred = model.predict(X_val_fold)\n",
        "    y_val_pred_classes = np.argmax(y_val_pred, axis=1)\n",
        "    y_val_true = np.argmax(y_val_fold, axis=1)\n",
        "\n",
        "    cm = confusion_matrix(y_val_true, y_val_pred_classes)\n",
        "    f1 = f1_score(y_val_true, y_val_pred_classes)\n",
        "    precision = precision_score(y_val_true, y_val_pred_classes)\n",
        "    recall = recall_score(y_val_true, y_val_pred_classes)\n",
        "\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fail', 'Pass'], yticklabels=['Fail', 'Pass'])\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.title(f'Confusion Matrix - Fold {fold}')\n",
        "    plt.show()\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "# 최종 모델 평가\n",
        "test_fail_images = load_images_from_folder(test_fail_dir, 0)\n",
        "test_pass_images = load_images_from_folder(test_pass_dir, 1)\n",
        "\n",
        "test_dataset = test_fail_images + test_pass_images\n",
        "X_test, y_test = zip(*test_dataset)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "ZRWIjEDvX0u2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}