{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3EveoivnoHe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from torch.utils.data import ConcatDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Focal Loss Definition\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = F.cross_entropy(inputs, targets, reduction=\"none\")\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        F_loss = (1 - pt) ** self.gamma * BCE_loss\n",
        "        return F_loss.mean() if self.reduction == 'mean' else F_loss.sum()\n",
        "\n",
        "# Custom dataset class for augmented images\n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, target_length=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if os.path.isfile(os.path.join(root_dir, fname))]\n",
        "\n",
        "        if target_length and len(self.image_paths) < target_length:\n",
        "            self.image_paths *= (target_length // len(self.image_paths)) + 1\n",
        "            self.image_paths = self.image_paths[:target_length]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx % len(self.image_paths)]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        label = 1 if 'pass' in img_path else 0\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Paths (adjust as needed)\n",
        "train_fail_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_SHAFT/iteration_1/train/fail'\n",
        "train_pass_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_SHAFT/iteration_1/train/pass'\n",
        "test_fail_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_SHAFT/iteration_1/Test/fail'\n",
        "test_pass_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/Processed_Data_SHAFT/iteration_1/Test/pass'\n",
        "\n",
        "# Define data augmentations and transformations\n",
        "augment_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create balanced datasets\n",
        "train_fail_dataset = AugmentedDataset(train_fail_dir, transform=augment_transform)\n",
        "train_pass_dataset = AugmentedDataset(train_pass_dir, transform=augment_transform, target_length=len(train_fail_dataset))\n",
        "train_dataset = ConcatDataset([train_fail_dataset, train_pass_dataset])\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Test datasets\n",
        "test_fail_dataset = AugmentedDataset(test_fail_dir, transform=test_transform)\n",
        "test_pass_dataset = AugmentedDataset(test_pass_dir, transform=test_transform)\n",
        "test_dataset = ConcatDataset([test_fail_dataset, test_pass_dataset])\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load a pre-trained ResNet model and modify the final layer\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.fc = nn.Linear(model.fc.in_features, 2)\n",
        "\n",
        "# Define device, loss, and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "criterion = FocalLoss(gamma=2)  # Focal Loss to focus more on difficult examples\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Training function\n",
        "def train(model, loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(loader)}\")\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    return all_preds, all_labels\n",
        "\n",
        "# Train the model\n",
        "train(model, train_loader, criterion, optimizer, epochs=10)\n",
        "\n",
        "# Evaluate on test data\n",
        "preds, labels = evaluate(model, test_loader)\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Fail', 'Pass'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.show()\n"
      ]
    }
  ]
}
