{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9e51ZTHpncT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# 경로 설정\n",
        "pass_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/SHAFT/SHAFT_합격이미지'\n",
        "fail_dir = '/content/drive/MyDrive/data/태림산업 이미지셋/SHAFT/SHAFT_불량이미지'\n",
        "img_height, img_width = 224, 224\n",
        "batch_size = 16  # batch_size 변수 정의\n",
        "\n",
        "# 데이터 증강 생성기 설정\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# 부스트래핑 반복 횟수\n",
        "n_iterations = 4\n",
        "accuracy_scores = []\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    # 랜덤으로 30개 이미지 추출\n",
        "    pass_images = random.sample(os.listdir(pass_dir), 30)\n",
        "    fail_images = random.sample(os.listdir(fail_dir), 30)\n",
        "\n",
        "    X, y = [], []\n",
        "    for img_name in pass_images:\n",
        "        img_path = os.path.join(pass_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (img_height, img_width))\n",
        "        X.append(img)\n",
        "        y.append(1)  # pass label\n",
        "\n",
        "    for img_name in fail_images:\n",
        "        img_path = os.path.join(fail_dir, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, (img_height, img_width))\n",
        "        X.append(img)\n",
        "        y.append(0)  # fail label\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # 데이터셋 분할\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
        "\n",
        "    # 데이터 증강을 통해 학습 데이터 증가\n",
        "    X_augmented, y_augmented = [], []\n",
        "    for xi, yi in zip(X_train, y_train):\n",
        "        xi = np.expand_dims(xi, axis=0)\n",
        "        gen = datagen.flow(xi, np.array([yi]), batch_size=1)\n",
        "        for _ in range(10):  # 각 이미지당 10개 증강\n",
        "            augmented_x, augmented_y = next(gen)  # Python의 next() 함수 사용\n",
        "            X_augmented.append(augmented_x[0])\n",
        "            y_augmented.append(augmented_y[0])\n",
        "\n",
        "    X_augmented = np.array(X_augmented)\n",
        "    y_augmented = np.array(y_augmented)\n",
        "\n",
        "    # 모델 정의\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dropout(0.5),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # 모델 컴파일\n",
        "    model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # 조기 종료 설정\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    # 모델 학습\n",
        "    model.fit(\n",
        "        X_augmented, y_augmented,\n",
        "        epochs=20,\n",
        "        batch_size=batch_size,  # 정의된 batch_size 사용\n",
        "        validation_split=0.2,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # 모델 평가\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(int).flatten()\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "    print(f\"Iteration {i+1}/{n_iterations} - Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 평균 정확도 출력\n",
        "average_accuracy = np.mean(accuracy_scores)\n",
        "print(f\"Average Accuracy over {n_iterations} iterations: {average_accuracy:.4f}\")"
      ]
    }
  ]
}
